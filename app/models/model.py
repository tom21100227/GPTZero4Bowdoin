"""
This code a slight modification of perplexity by hugging face
https://huggingface.co/docs/transformers/perplexity

Both this code and the orignal code are published under the MIT license.

by Burhan Ul tayyab and Nicholas Chua
"""

import torch
import re
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from collections import OrderedDict

import spacy

def determine_device():
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():
        return "mps"
    else:
        return "cpu"

nlp = spacy.load("en_core_web_sm")

def split_sentences(text: str):
    doc = nlp(text)
    spacy_sentences = [sent.text for sent in doc.sents]
    # remove empty strings, strip leading and trailing whitespaces, and remove newlines
    spacy_sentences = [sent.strip() for sent in spacy_sentences if sent.strip()]
    return spacy_sentences

class GPT2PPL:
    def __init__(self, device=None, model_id="gpt2"):
        self.device = device if device is not None else determine_device()
        self.model_id = model_id
        self.model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
        self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id)

        self.max_length = self.model.config.n_positions
        self.stride = 512

    def getResults(self, threshold):
        if threshold < 60:
            label = 0
            return "The Text is generated by AI.", label
        elif threshold < 80:
            label = 0
            return "The Text is most probably contain parts which are generated by AI. (require more text for better Judgement)", label
        else:
            label = 1
            return "The Text is written by Human.", label

    def __call__(self, text):
        """
        Takes in a sentence split by full stop
        and print the perplexity of the total sentence

        split the lines based on full stop and find the perplexity of each sentence and print
        average perplexity

        Burstiness is the max perplexity of each sentence.
        """
        results = OrderedDict()

        total_valid_char = re.findall("[a-zA-Z0-9]+", text)
        total_valid_char = sum([len(x) for x in total_valid_char]) # finds len of all the valid characters a sentence

        if total_valid_char < 100:
            return {"status": "Please input more text (min 100 characters)"}, [0], ["",]

        fulltext_ppl = self.getPPL(text)
        print(f"Perplexity {fulltext_ppl}")
        results["Perplexity"] = fulltext_ppl

        lines = split_sentences(text)

        ppls = []
        for i, line in enumerate(lines):
            ppl = self.getPPL(line)
            ppls.append(ppl)

        results["Perplexity per line"] = sum(ppls)/len(ppls)

        results["Burstiness"] = max(ppls)

        out, label = self.getResults(results["Perplexity per line"])
        results["label"] = label

        return results, ppls, lines

    def getPPL(self,sentence):
        encodings = self.tokenizer(sentence, return_tensors="pt")
        seq_len = encodings.input_ids.size(1)

        nlls = [] # negative log likelihoods
        likelihoods = []
        prev_end_loc = 0
        for begin_loc in range(0, seq_len, self.stride):
            end_loc = min(begin_loc + self.max_length, seq_len)
            trg_len = end_loc - prev_end_loc
            input_ids = encodings.input_ids[:, begin_loc:end_loc].to(self.device)
            target_ids = input_ids.clone()
            target_ids[:, :-trg_len] = -100

            with torch.no_grad():
                outputs = self.model(input_ids, labels=target_ids)
                neg_log_likelihood = outputs.loss * trg_len
                likelihoods.append(neg_log_likelihood)

            nlls.append(neg_log_likelihood)

            prev_end_loc = end_loc
            if end_loc == seq_len:
                break
        ppl = int(torch.exp(torch.stack(nlls).sum() / end_loc))
        return ppl
